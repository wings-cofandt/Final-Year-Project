{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Personality_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NfUYq3D_hSW",
        "outputId": "6c566931-797a-4dfb-cd27-281cd8726c10"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8_-nqhf3t39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fba7e9a0-805e-48c3-914a-503024e02b66"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "from keras.applications.vgg16 import VGG16, decode_predictions, preprocess_input\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Dimensions of our images.\n",
        "img_width, img_height = 150, 150  #lowering computations\n",
        "\n",
        "train_data_dir = '/content/drive/MyDrive/images/dataimages'\n",
        "validation_data_dir = '/content/drive/MyDrive/images/Validation'\n",
        "test_data_dir = '/content/drive/MyDrive/images/test'\n",
        "nb_train_samples = 177 # 60\n",
        "nb_validation_samples = 114 # 40\n",
        "epochs = 20\n",
        "batch_size = 32\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)\n",
        "\n",
        "# Load pretrained VGG16 model.\n",
        "# The last (top) layers doing the final classification are not included.\n",
        "vgg16 = VGG16(weights='imagenet', input_shape=input_shape, include_top=False)\n",
        "\n",
        "# Freeze the weights for the first layers.\n",
        "for layer in vgg16.layers[:17]:\n",
        "    layer.trainable = False\n",
        "# vgg16.summary()\n",
        "\n",
        "# Add custom layers.\n",
        "x = vgg16.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(units=64, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(units=3, activation=\"softmax\")(x)\n",
        "print(vgg16.input)\n",
        "# Create final model.\n",
        "#model = Model(inputs = vgg16.input, output = predictions)\n",
        "model = Model(inputs=vgg16.input, outputs=predictions)\n",
        "model.compile(loss='CategoricalCrossentropy',\n",
        "              optimizer=SGD(lr=0.001, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "history = model.summary()\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "  model, to_file='/content/model.png', show_shapes=True, show_dtype=False,\n",
        "  show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96\n",
        "  )\n",
        "\n",
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "print(test_generator)\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 150, 150, 3), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\")\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                524352    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 15,239,235\n",
            "Trainable params: 2,884,355\n",
            "Non-trainable params: 12,354,880\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 177 images belonging to 3 classes.\n",
            "Found 114 images belonging to 3 classes.\n",
            "Found 9 images belonging to 3 classes.\n",
            "<keras.preprocessing.image.DirectoryIterator object at 0x7f2124ebed90>\n",
            "Epoch 1/20\n",
            "5/5 [==============================] - 8s 1s/step - loss: 1.2445 - accuracy: 0.3784 - val_loss: 1.1218 - val_accuracy: 0.3125\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 5s 1s/step - loss: 1.1114 - accuracy: 0.4484 - val_loss: 1.0865 - val_accuracy: 0.4479\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.9065 - accuracy: 0.5700 - val_loss: 1.0763 - val_accuracy: 0.3750\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.7557 - accuracy: 0.7016 - val_loss: 1.0333 - val_accuracy: 0.3750\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.6828 - accuracy: 0.7107 - val_loss: 1.0648 - val_accuracy: 0.3438\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.5746 - accuracy: 0.7891 - val_loss: 1.0598 - val_accuracy: 0.3542\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.5508 - accuracy: 0.7528 - val_loss: 1.0947 - val_accuracy: 0.3542\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.4962 - accuracy: 0.8075 - val_loss: 0.9743 - val_accuracy: 0.4167\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.4925 - accuracy: 0.8236 - val_loss: 1.0264 - val_accuracy: 0.4375\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.3503 - accuracy: 0.8883 - val_loss: 1.1257 - val_accuracy: 0.4583\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.3111 - accuracy: 0.9043 - val_loss: 1.0759 - val_accuracy: 0.4167\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.2809 - accuracy: 0.8897 - val_loss: 0.9960 - val_accuracy: 0.4688\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.3051 - accuracy: 0.8661 - val_loss: 1.2417 - val_accuracy: 0.4167\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.2601 - accuracy: 0.9121 - val_loss: 1.0261 - val_accuracy: 0.5104\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.1885 - accuracy: 0.9629 - val_loss: 1.0125 - val_accuracy: 0.5625\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.2468 - accuracy: 0.9092 - val_loss: 1.0357 - val_accuracy: 0.5104\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.2146 - accuracy: 0.9134 - val_loss: 1.2323 - val_accuracy: 0.4479\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.2113 - accuracy: 0.9304 - val_loss: 1.1916 - val_accuracy: 0.4688\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.2037 - accuracy: 0.9244 - val_loss: 1.2164 - val_accuracy: 0.4167\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 5s 1s/step - loss: 0.1204 - accuracy: 0.9742 - val_loss: 1.2271 - val_accuracy: 0.4062\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2124ebe4d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jqSSIBF2pMC6",
        "outputId": "c8aab9d7-e5b6-4fba-87dc-98a83914a658"
      },
      "source": [
        "img = image.load_img('/content/drive/MyDrive/images/test/Good Personality/1.jpg', target_size=(150, 150))\n",
        "labels = ['Averge Personality', 'Fair Personality', 'Good Personality']\n",
        "array = image.img_to_array(img)\n",
        "array = np.expand_dims(array, axis=0)\n",
        "# print(array)\n",
        "preds = model.predict(preprocess_input(array))\n",
        "# res = decode_predictions(preds, top=1)[0]\n",
        "\n",
        "array_preds = max(preds)\n",
        "(array_preds)\n",
        "index_pred = np.argmax(array_preds)\n",
        "labels[index_pred]\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Good Personality'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}