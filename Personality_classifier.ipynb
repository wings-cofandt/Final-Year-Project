{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Personality classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NfUYq3D_hSW",
        "outputId": "a674f1d9-abb5-4f73-9bba-f91b982c3baf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8_-nqhf3t39"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "from keras.applications.vgg16 import VGG16, decode_predictions, preprocess_input\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Dimensions of our images.\n",
        "img_width, img_height = 150, 150  #lowering computations\n",
        "\n",
        "train_data_dir = '/content/drive/MyDrive/training'\n",
        "validation_data_dir = '/content/drive/MyDrive/Validation'\n",
        "test_data_dir = '/content/drive/MyDrive/test'\n",
        "nb_train_samples = 177 # 60\n",
        "nb_validation_samples = 114 # 40\n",
        "epochs = 5\n",
        "batch_size = 32\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)\n",
        "\n",
        "# Load pretrained VGG16 model.\n",
        "# The last (top) layers doing the final classification are not included.\n",
        "vgg16 = VGG16(weights='imagenet', input_shape=input_shape, include_top=False)\n",
        "\n",
        "# Freeze the weights for the first layers.\n",
        "for layer in vgg16.layers[:17]:\n",
        "    layer.trainable = False\n",
        "# vgg16.summary()\n",
        "\n",
        "# Add custom layers.\n",
        "x = vgg16.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(units=64, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(units=3, activation=\"softmax\")(x)\n",
        "print(vgg16.input)\n",
        "# Create final model.\n",
        "#model = Model(inputs = vgg16.input, output = predictions)\n",
        "model = Model(inputs=vgg16.input, outputs=predictions)\n",
        "model.compile(loss='CategoricalCrossentropy',\n",
        "              optimizer=SGD(lr=0.001, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "history = model.summary()\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "  model, to_file='/content/model.png', show_shapes=True, show_dtype=False,\n",
        "  show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96\n",
        "  )\n",
        "\n",
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "print(test_generator)\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jqSSIBF2pMC6",
        "outputId": "7c453282-1ff2-410e-990d-f1d410381b1e"
      },
      "source": [
        "img = image.load_img('/content/drive/MyDrive/test/Fair Personality/9.jpg', target_size=(150, 150))\n",
        "labels = ['Averge personality', 'fair personality', 'good personality']\n",
        "array = image.img_to_array(img)\n",
        "array = np.expand_dims(array, axis=0)\n",
        "# print(array)\n",
        "preds = model.predict(preprocess_input(array))\n",
        "# res = decode_predictions(preds, top=1)[0]\n",
        "\n",
        "array_preds = max(preds)\n",
        "(array_preds)\n",
        "index_pred = np.argmax(array_preds)\n",
        "labels[index_pred]\n",
        "# for arr,labels in test_generator:\n",
        "#   # arr.shape\n",
        "#   # print(arr)\n",
        "#   # print(labels)\n",
        "#   # print/(labels)\n",
        "#   # plt.imshow(arr)\n",
        "#   # print('****')\n",
        "#   # print(arr)\n",
        "#   res = model.predict(arr)\n",
        "#   # print(res)learning_rate\n",
        "#   #print('****')\n",
        "\n",
        "\n",
        "# # res = model.predict(image_test)\n",
        "# # print(res)\n",
        "\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'fair personality'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    }
  ]
}